"""API endpoints for ingestion configuration management.

Note: Configuration is now handled through SurrealDB schema definitions.
These endpoints are kept for backward compatibility but return minimal data.
"""
from typing import List, Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from pydantic import BaseModel
from sqlalchemy.orm import Session

from server.auth.dependencies import get_token_from_header
from server.auth.service import get_access_control
from server.jobs import get_jobs_db, UploadBatch
from server.logging_config import get_logger

logger = get_logger(name=__name__)

router = APIRouter(prefix="/v2/config", tags=["Configuration"])


# ============== Response Models ==============

class IngestionConfigSummary(BaseModel):
    """Summary response for ingestion config."""
    id: int
    name: str
    description: Optional[str]
    data_source: str
    source_parquet_name: str
    target_table_name: str
    primary_key_columns: List[str]
    version_strategy: str
    processing_order: int
    is_active: bool
    field_mappings_count: int


class IngestionConfigListResponse(BaseModel):
    """Response for list of ingestion configs."""
    configs: List[IngestionConfigSummary]
    total: int


class ParquetFileInfo(BaseModel):
    """Info about a parquet file."""
    filename: str
    path: str
    size_bytes: int
    modified_at: float


class ParquetFilesResponse(BaseModel):
    """Response for parquet files list."""
    batch_id: int
    files: List[ParquetFileInfo]
    total: int


# ============== Endpoints ==============

@router.get("/ingestion", response_model=IngestionConfigListResponse)
async def list_ingestion_configs(
    data_source: Optional[str] = Query(None, description="Filter by data source (issues, controls, actions)"),
    token: str = Depends(get_token_from_header),
    db: Session = Depends(get_jobs_db),
):
    """
    List all ingestion configurations.

    Note: Configuration is now handled through SurrealDB schema.
    Returns empty list as configs are embedded in the schema.
    """
    access = await get_access_control(token)

    if not access.hasPipelinesIngestionAccess:
        raise HTTPException(status_code=403, detail="Access denied")

    # Configuration is now embedded in SurrealDB schema
    return IngestionConfigListResponse(configs=[], total=0)


@router.get("/parquet-files/{batch_id}", response_model=ParquetFilesResponse)
async def get_parquet_files(
    batch_id: int,
    token: str = Depends(get_token_from_header),
    db: Session = Depends(get_jobs_db),
):
    """
    Get list of parquet files for a batch.

    Returns the parquet files generated by validation for this batch.

    - **batch_id**: The upload batch ID
    """
    from pathlib import Path
    from ... import storage

    access = await get_access_control(token)

    if not access.hasPipelinesIngestionAccess:
        raise HTTPException(status_code=403, detail="Access denied")

    # Get batch
    batch = db.query(UploadBatch).filter_by(id=batch_id).first()
    if not batch:
        raise HTTPException(status_code=404, detail=f"Batch {batch_id} not found")

    # Get parquet files from preprocessed directory
    preprocessed_path = storage.get_preprocessed_batch_path(batch.upload_id, batch.data_type)
    files = []

    if preprocessed_path.exists():
        for file_path in preprocessed_path.glob("*.parquet"):
            stat = file_path.stat()
            files.append(ParquetFileInfo(
                filename=file_path.name,
                path=str(file_path),
                size_bytes=stat.st_size,
                modified_at=stat.st_mtime,
            ))

    return ParquetFilesResponse(
        batch_id=batch_id,
        files=files,
        total=len(files)
    )
